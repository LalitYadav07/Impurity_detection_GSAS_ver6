---
emoji: üî¨
colorFrom: green
colorTo: blue
sdk: docker
pinned: false
---

# GSAS-II Impurity Detector (v7.0)

This platform leverages **GSAS-II** to automate the discovery and refinement of impurity phases in powder diffraction data. It combines machine learning candidate screening with rigorous Rietveld refinement to provide high-confidence phase identification.

---

## üöÄ Quick Start (Hugging Face / Cloud)

The easiest way to use the tool is via our hosted [Hugging Face Space](https://huggingface.co/spaces/Lalityadav07/phase_detection).

1. Upload your `.dat` or `.xye` file.
2. Upload your `.instprm` file.
3. Select an Example (LK-99 or TbSSL) for a quick demo.
4. Pulse the **Start Pipeline** button.

---

## üõ†Ô∏è Local Installation (Windows & Linux)

We use **Pixi** to manage all scientific dependencies and GSAS-II binaries in an isolated environment.

1. **Install Pixi**: [pixi.sh](https://pixi.sh)
2. **Clone the Repo**:

    ```bash
    git clone https://github.com/Lalityadav07/Impurity_detection_GSAS_version7.git
    cd Impurity_detection_GSAS_version7
    ```

3. **Run Setup**:
    - **Windows**: `.\setup.ps1`
    - **Linux**: `./setup.sh`

This will clone GSAS-II, build the necessary numerical binaries (`LATTIC`, `convcell`), and solve all Python dependencies (PyTorch, Pymatgen, etc.).

---

## üíª Usage

### üåê Web UI (Streamlit)

The Web UI provides a premium dashboard for monitoring runs, viewing live logs, and exploring results.

```bash
pixi run ui
```

Access the dashboard at `http://localhost:8501`.

### ‚å®Ô∏è Command Line Interface (CLI)

For batch processing or high-performance environments (HPC), use the CLI tool directly.

```bash
# Verify the environment with a dry-run
pixi run cli-test

# Run a full pipeline with a configuration file
pixi run cli-run -- --config my_pipeline_config.yaml
```

---

## üìÇ Project Architecture

### Directory Structure

- `app.py`: Main Streamlit application.
- `scripts/`: Implementation of the discovery pipeline and ML screening.
- `GSAS-II/`: The core GSAS-II scientific engine (git-ignored submodule).
- `ML_components/`: Pre-trained models for Stage-3 screening.
- `data/database_aug/`: Crystallographic database (required for screening).
- `runs/`: Output directory for generated artifacts and logs.

### Key Components

- **ML Screening**: Rapid candidate selection using element family and spacegroup filters. Now includes detailed metadata (Compound Name, Space Group).
- **Lattice Nudging**: Adaptive lattice parameter optimization before Rietveld.
- **Sequential Passes**: Each pass identifies the next most likely impurity, refining the global model until convergence. Multi-pass results are now viewable in organized expanders.
- **Decision Engine**: Visualizes the internal "Knee Filter" logic used to prune candidates.

---

## ü§ù Contributing

Scientific contributions, bug reports, and database updates are welcome. Please ensure that all changes maintain compatibility with the Pixi environment.

---

## üõ†Ô∏è Troubleshooting & Technical Notes

### 1. Missing GSAS-II Binaries

If you see `*** ERROR: Unable to find GSAS-II binaries`, it usually means the Fortran/C extensions weren't compiled or linked correctly.

- **Solution**: Run `.\setup.ps1` (Windows) or `./setup.sh` (Linux) again. The scripts are designed to "bridge" the compiled binaries into the Python path.

### 2. Python Version

This project requires **Python 3.12**.

### 3. Database Download

The database is ~2.3GB. If the download fails in the UI, you can manually download it from the link provided in the logs and extract it to `data/database_aug/`.

## üåê API Access & Custom GPT Integration (v7.1)

The v7.1 version includes a REST API that allows you to integrate the GSAS-II pipeline with Custom GPTs and external tools.

### 1. Connection Details

- **Base URL**: `https://<your-hf-space-id>.hf.space/api`
- **OpenAPI Spec**: Available at `https://<your-hf-space-id>.hf.space/openapi.json`
- **Auth**: Set a `GSAS_API_KEY` in your Hugging Face Space secrets. External tools must include this in the `X-API-Key` header.

### 2. Custom GPT Setup

To use this with a Custom GPT:

1. Create a new "Action" in your GPT configuration.
2. Import the OpenAPI schema from the Space (or copy-paste from `openapi_v7.1.json` generated by `scripts/export_openapi.py`).
3. Set the Authentication type to "API Key" and use the `X-API-Key` header.
4. Now you can say: *"Analyze this diffraction file for TiO2 impurities"* and the GPT will handle the upload and status polling automatically.

### 3. API Endpoints

- `POST /api/run`: Submit data and start detection.
- `GET /api/status/{run_id}`: Poll progress (0-100%).
- `GET /api/results/{run_id}`: Retrieve final summary and download links.
